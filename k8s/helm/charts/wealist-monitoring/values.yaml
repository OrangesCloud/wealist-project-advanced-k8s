# =============================================================================
# weAlist Monitoring Stack - Default Values
# =============================================================================
# Prometheus, Grafana, Loki, Promtail 기반 모니터링 스택
#
# 환경별 설정은 values-develop-registry-local.yaml 등에서 오버라이드

# Global settings
global:
  namespace: wealist

# =============================================================================
# External Secrets (ESO) Configuration
# =============================================================================
# enabled: true → ExternalSecret에서 시크릿 가져옴 (dev/prod)
# enabled: false → values 또는 로컬 Secret 사용 (dev/localhost)
externalSecrets:
  enabled: false

# =============================================================================
# Prometheus - Metrics Collection
# =============================================================================
prometheus:
  enabled: true

  image:
    repository: prom/prometheus
    tag: "v2.48.0"
    pullPolicy: IfNotPresent

  replicas: 1

  service:
    type: ClusterIP
    port: 9090

  persistence:
    enabled: true
    storageClass: ""
    size: 10Gi
    # Kind/로컬 환경용 hostPath 설정
    hostPath:
      enabled: false
      path: /data/prometheus

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  config:
    scrapeInterval: 15s
    evaluationInterval: 15s
    retentionTime: 7d
    # Sub-path configuration (for Gateway access via /monitoring/prometheus)
    externalUrl: "/monitoring/prometheus"

  # Alert 규칙 및 Alertmanager 설정
  alerting:
    enabled: false  # Enable in production
    alertmanager:
      enabled: false
      host: alertmanager
      port: 9093

  # 스크래핑 대상 서비스들
  scrapeTargets:
    # Go Services
    userService:
      enabled: true
      host: user-service
      port: 8081
      path: /metrics
    boardService:
      enabled: true
      host: board-service
      port: 8000
      path: /metrics
    chatService:
      enabled: true
      host: chat-service
      port: 8001
      path: /metrics
    notiService:
      enabled: true
      host: noti-service
      port: 8002
      path: /metrics
    storageService:
      enabled: true
      host: storage-service
      port: 8003
      path: /metrics
    videoService:
      enabled: true
      host: video-service
      port: 8004
      path: /metrics
    # Spring Boot Service
    authService:
      enabled: true
      host: auth-service
      port: 8080
      path: /actuator/prometheus

  # =============================================================================
  # Remote Write & Exemplars (2025 Best Practice)
  # =============================================================================
  # Tempo Metrics Generator에서 메트릭을 수신하기 위해 필요
  remoteWriteReceiver:
    enabled: false  # prod에서 true로 활성화
  # Exemplar 저장 활성화 (Metrics → Traces 연결)
  exemplarStorage:
    enabled: false  # prod에서 true로 활성화

# =============================================================================
# Loki - Log Aggregation
# =============================================================================
loki:
  enabled: true

  image:
    repository: grafana/loki
    tag: "2.9.2"
    pullPolicy: IfNotPresent

  replicas: 1

  service:
    type: ClusterIP
    port: 3100

  persistence:
    enabled: true
    storageClass: ""
    size: 10Gi

  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"

  config:
    retentionPeriod: 168h  # 7 days
    ingestionRateMB: 10
    ingestionBurstSizeMB: 20
    # S3 Storage Backend (prod용)
    s3:
      enabled: false
      bucket: ""
      region: ""

# =============================================================================
# Promtail - Log Collector (Legacy - use Alloy instead)
# =============================================================================
promtail:
  enabled: true

  image:
    repository: grafana/promtail
    tag: "2.9.2"
    pullPolicy: IfNotPresent

  resources:
    requests:
      memory: "64Mi"
      cpu: "25m"
    limits:
      memory: "128Mi"
      cpu: "100m"

  config:
    # Loki endpoint
    lokiUrl: http://loki:3100/loki/api/v1/push

# =============================================================================
# Alloy - Modern Log Collector (Promtail Replacement)
# =============================================================================
# Grafana Alloy is the successor to Promtail with improved performance
# and native support for all Grafana LGTM stack components
alloy:
  enabled: false  # Enable in prod (replaces Promtail)

  image:
    repository: grafana/alloy
    tag: "v1.12.1"
    pullPolicy: IfNotPresent

  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"

# =============================================================================
# Grafana - Visualization Dashboard
# =============================================================================
grafana:
  enabled: true

  image:
    repository: grafana/grafana
    tag: "10.2.2"
    pullPolicy: IfNotPresent

  replicas: 1

  service:
    type: ClusterIP
    port: 3000
    # NodePort for local access (Kind)
    nodePort: 30001

  persistence:
    enabled: true
    storageClass: ""
    size: 5Gi

  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"

  # Admin credentials
  admin:
    user: admin
    password: admin  # Override in production!

  config:
    allowSignUp: false
    # Sub-path configuration (for Gateway access via /monitoring/grafana)
    # %(protocol)s://%(domain)s:%(http_port)s 는 Grafana가 자동으로 치환
    rootUrl: "%(protocol)s://%(domain)s:%(http_port)s/monitoring/grafana"
    serveFromSubPath: "true"

  # Additional Datasources (확장용)
  additionalDatasources:
    # Elasticsearch (ELK 스택 연동용)
    elasticsearch:
      enabled: false  # ELK 배포 시 true로 변경
      url: "http://elasticsearch:9200"
      index: "logstash-*"
      # Production에서는 AWS OpenSearch 사용 가능
      # url: "https://search-xxx.ap-northeast-2.es.amazonaws.com"

# =============================================================================
# Monitoring Ingress - External Access via domain/monitoring/*
# =============================================================================
# Note: Named 'monitoringIngress' to avoid conflict with infrastructure 'ingress'
monitoringIngress:
  enabled: false  # Enable in environments with Ingress controller
  className: nginx
  annotations: {}
  hosts: []
  # - host: dev.wealist.co.kr
  tls: []

# =============================================================================
# PostgreSQL Exporter - External PostgreSQL Metrics
# =============================================================================
postgresExporter:
  enabled: false  # Enable in environments with external PostgreSQL

  image:
    repository: prometheuscommunity/postgres-exporter
    tag: v0.15.0

  service:
    port: 9187

  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"

  # Connection to external PostgreSQL
  config:
    host: "172.18.0.1"
    port: 5432
    user: "postgres"
    database: "postgres"
    sslmode: "disable"

# =============================================================================
# Redis Exporter - External Redis Metrics
# =============================================================================
redisExporter:
  enabled: false  # Enable in environments with external Redis

  image:
    repository: oliver006/redis_exporter
    tag: v1.55.0

  service:
    port: 9121

  resources:
    requests:
      memory: "32Mi"
      cpu: "25m"
    limits:
      memory: "64Mi"
      cpu: "50m"

  # Connection to external Redis
  config:
    host: "172.18.0.1"
    port: 6379

# =============================================================================
# kube-state-metrics - Kubernetes Objects State Metrics
# =============================================================================
# Generates metrics about Kubernetes objects (pods, nodes, deployments, etc.)
# Required for Kubernetes Cluster dashboard and Service Health Overview
kubeStateMetrics:
  enabled: false  # Enable in prod environment

  image:
    repository: registry.k8s.io/kube-state-metrics/kube-state-metrics
    tag: v2.10.1
    pullPolicy: IfNotPresent

  service:
    port: 8080

  telemetryPort: 8081

  # Optional: limit to specific namespaces (empty = all namespaces)
  namespaces: []

  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"

# =============================================================================
# node-exporter - Node System Metrics
# =============================================================================
# Exports node-level metrics (CPU, memory, disk, network)
# Required for node resource usage in Kubernetes Cluster dashboard
nodeExporter:
  enabled: false  # Enable in prod environment

  image:
    repository: prom/node-exporter
    tag: v1.7.0
    pullPolicy: IfNotPresent

  service:
    port: 9100

  resources:
    requests:
      memory: "32Mi"
      cpu: "25m"
    limits:
      memory: "64Mi"
      cpu: "100m"

# =============================================================================
# ArgoCD Metrics
# =============================================================================
argocd:
  metrics:
    enabled: false  # Enable in prod environment

# =============================================================================
# Shared Secrets (for exporters)
# =============================================================================
shared:
  secrets:
    DB_PASSWORD: ""
    REDIS_PASSWORD: ""

# =============================================================================
# k6 Performance Testing Configuration
# =============================================================================
# k6 성능 테스트를 Kubernetes에서 실행하기 위한 설정
# 참고: https://grafana.com/docs/k6/latest/
k6:
  enabled: false  # Production에서만 true

  image:
    repository: grafana/k6
    tag: "0.49.0"
    pullPolicy: IfNotPresent

  # k6 Job 리소스 제한
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  # Prometheus Remote Write 설정
  # k6 실행 시 --out experimental-prometheus-rw 옵션 사용
  prometheus:
    remoteWriteUrl: "http://prometheus:9090/api/v1/write"

  # 테스트 시나리오 기본 설정
  scenarios:
    load:
      enabled: true
      duration: "5m"
      vus: 20
      description: "Normal load test"
    stress:
      enabled: true
      maxVUs: 300
      duration: "30m"
      description: "Stress test to find breaking point"
    spike:
      enabled: true
      peakVUs: 500
      duration: "10m"
      description: "Spike test for sudden traffic bursts"

  # 테스트 대상 서비스 엔드포인트
  endpoints:
    baseUrl: "http://istio-ingressgateway.istio-system.svc.cluster.local"
    services:
      - name: board
        path: /svc/board
        healthPath: /health/live
      - name: user
        path: /svc/user
        healthPath: /health/live
      - name: chat
        path: /svc/chat
        healthPath: /health/live
      - name: noti
        path: /svc/noti
        healthPath: /health/live
      - name: storage
        path: /svc/storage
        healthPath: /health/live
      - name: video
        path: /svc/video
        healthPath: /health/live

  # SLA 임계값 (Alert과 연동)
  thresholds:
    latencyP95Ms: 500
    latencyP99Ms: 1000
    errorRatePercent: 1
    availabilityPercent: 99.9

# =============================================================================
# OpenTelemetry Collector - Trace Collection Gateway
# =============================================================================
# OTEL Collector를 Gateway 패턴으로 배포하여 서비스에서 전송된 trace를 수집
# 2025 트렌드: Hybrid Pattern (DaemonSet for logs via Promtail + Deployment for traces)
otelCollector:
  enabled: false  # Enable in local-kind and prod

  image:
    repository: otel/opentelemetry-collector-contrib
    tag: "0.114.0"  # 2025-12 최신 안정 버전
    pullPolicy: IfNotPresent

  replicas: 1  # prod에서 2로 증가

  service:
    otlpGrpcPort: 4317
    otlpHttpPort: 4318
    metricsPort: 8888

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  # Collector 설정
  config:
    # Batch processor 설정
    batchTimeout: 5s
    sendBatchSize: 1000
    # Memory limiter
    memoryLimitMiB: 400
    spikeLimitMiB: 100

  # =============================================================================
  # Tail Sampling (2025 Best Practice)
  # =============================================================================
  # Head sampling과 달리 trace 완료 후 샘플링 결정
  # 에러/슬로우 트레이스 100% 유지 + 정상 트래픽 샘플링
  tailSampling:
    enabled: false  # prod에서 true로 활성화
    # 샘플링 결정 대기 시간 (trace 완료까지 대기)
    decisionWaitSeconds: 10
    # 동시에 처리할 trace 수 (메모리 사용량에 영향)
    numTraces: 100000
    # 초당 예상 새 trace 수
    expectedNewTracesPerSec: 1000
    # 정책별 설정
    policies:
      # 에러 트레이스 100% 유지
      errorSampling: true
      # 느린 트레이스 유지 기준 (ms)
      latencyThresholdMs: 1000
      # 정상 트래픽 샘플링 비율 (%)
      defaultSamplingPercentage: 10

# =============================================================================
# Tempo - Distributed Tracing Backend
# =============================================================================
# Grafana Tempo를 사용하여 분산 추적 저장 및 쿼리
# Traces-Logs Correlation을 위해 Loki와 연동
tempo:
  enabled: false  # Enable in local-kind and prod

  image:
    repository: grafana/tempo
    tag: "2.9.0"  # 2025-12 최신 안정 버전
    pullPolicy: IfNotPresent

  replicas: 1

  service:
    httpPort: 3200      # Query API
    otlpGrpcPort: 4317  # OTLP gRPC receiver
    otlpHttpPort: 4318  # OTLP HTTP receiver

  persistence:
    enabled: true
    storageClass: ""
    size: 10Gi

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  config:
    # Trace 보관 기간
    retentionPeriod: 168h  # 7 days
    # 로컬 스토리지 백엔드
    backend: local
    # S3 백엔드 (prod용)
    s3:
      enabled: false
      bucket: ""
      region: ""

  # =============================================================================
  # Metrics Generator (2025 Best Practice)
  # =============================================================================
  # Trace 데이터에서 자동으로 RED 메트릭 생성
  # Prometheus로 전송하여 별도 instrumentation 없이 메트릭 수집
  metricsGenerator:
    enabled: false  # prod에서 true로 활성화
    # Prometheus remote write URL (routePrefix 포함 필요)
    # 예: prometheus.config.routePrefix가 /api/monitoring/prometheus인 경우:
    # http://prometheus:9090/api/monitoring/prometheus/api/v1/write
    remoteWriteUrl: "http://prometheus:9090/api/v1/write"
    # Span Metrics: Rate, Error, Duration 메트릭 생성
    spanMetrics:
      enabled: true
      dimensions:
        - service.name
        - http.method
        - http.status_code
        - http.route
      enableTargetInfo: true
    # Service Graphs: 서비스 간 의존성 메트릭
    serviceGraphs:
      enabled: true
      dimensions:
        - service.name
      enableClientServerPrefix: true
      enableVirtualNodeLabel: true
    # Local Blocks: TraceQL Metrics 지원
    localBlocks:
      enabled: true

